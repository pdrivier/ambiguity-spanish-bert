{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08dafd87",
   "metadata": {},
   "source": [
    "## Language Model Representations of Ambiguous (Spanish) Nouns in Context\n",
    "\n",
    "Here, we load monolingual Spanish-trained, and multilingual large language models (LLMs) from the [BERT/BETO](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased) family, and we use them to compute vector representations for target ambiguous Spanish nouns. To do so, we also load a dataframe of sentence pairs in Spanish, where each pair contains a target ambiguous noun whose sense is disambiguated by either an adjective or a verb (termed context cue). This context cue marks the only difference across a given pair of sentences. Context cues have been chosen such that sometimes the sentence pair evokes the same sense for the target word, **or** evokes different (homonymous or polysemous) senses for the target word. \n",
    "\n",
    "We run each (tokenized version of each) sentence through each model, and extract the vector representation, or embedding, for the target noun from each of the model's layers. We then compute and store the cosine distances between the target word embeddings from the first and second sentences of the pair. \n",
    "\n",
    "Here is a list of models we examined: \n",
    "\n",
    "* **BETO-cased** .... Cañete et al. (2020) *ICLR* [hugging-face](https://huggingface.co/dccuchile/bert-base-spanish-wwm-cased) - [paper](https://arxiv.org/pdf/2308.02976.pdf)\n",
    "* **BETO-uncased** .... Cañete et al. (2020) *ICLR* [hugging-face](https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased) - [paper](https://arxiv.org/pdf/2308.02976.pdf)\n",
    "* **BERT-base-multilingual-cased\"** .... Devlin et al. (2019) *arXiv* [hugging-face](https://huggingface.co/google-bert/bert-base-multilingual-cased) -  [training-details](https://github.com/google-research/bert/blob/master/multilingual.md#list-of-languages) - [paper](https://arxiv.org/pdf/1810.04805.pdf)\n",
    "* **ROBERTa-BNE-base (MaRIa)** .... Gutiérrez-Fandiño et al. (2022) *Procesamiento del Lenguaje Natural* [hugging-face](https://huggingface.co/PlanTL-GOB-ES/roberta-base-bne) - [paper](https://arxiv.org/pdf/2107.07253.pdf)\n",
    "* **ROBERTa-BNE-large (MaRIa)** .... Gutiérrez-Fandiño et al. (2022) *Procesamiento del Lenguaje Natural* - [hugging-face](https://huggingface.co/PlanTL-GOB-ES/roberta-large-bne) - [training-details](https://github.com/PlanTL-GOB-ES/lm-spanish?tab=readme-ov-file) - [paper](https://arxiv.org/pdf/2107.07253.pdf)\n",
    "* **XLM-ROBERTa-base** .... Conneau et al. (2020) *ACL* - [hugging-face](https://huggingface.co/FacebookAI/xlm-roberta-base) - [training-details](https://github.com/facebookresearch/fairseq/tree/main/examples/xlmr) - [paper](https://arxiv.org/pdf/1911.02116.pdf)\n",
    "* **ALBETO-tiny** .... Cañete et al. (2023) *arXiv* - [hugging-face](https://huggingface.co/dccuchile/albert-tiny-spanish) - [paper](https://arxiv.org/pdf/2204.09145.pdf)\n",
    "* **ALBETO-base** .... Cañete et al. (2023) *arXiv* - [hugging-face](https://huggingface.co/dccuchile/albert-base-spanish) - [paper](https://arxiv.org/pdf/2204.09145.pdf)\n",
    "* **ALBETO-large** .... Cañete et al. (2023) *arXiv* - [hugging-face](https://huggingface.co/dccuchile/albert-large-spanish) - [paper](https://arxiv.org/pdf/2204.09145.pdf)\n",
    "* **ALBETO-xlarge** .... Cañete et al. (2023) *arXiv* - [hugging-face](https://huggingface.co/dccuchile/albert-xlarge-spanish) - [paper](https://arxiv.org/pdf/2204.09145.pdf)\n",
    "* **ALBETO-xxlarge** .... Cañete et al. (2023) *arXiv* -  [hugging-face](https://huggingface.co/dccuchile/albert-xxlarge-spanish) - [paper](https://arxiv.org/pdf/2204.09145.pdf)\n",
    "* **DistilBETO-uncased** .... Cañete et al. (2023) *arXiv* -  [hugging-face](https://huggingface.co/dccuchile/distilbert-base-spanish-uncased/tree/main) - [paper](https://arxiv.org/pdf/2204.09145.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66550e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'  # makes figs nicer!\n",
    "\n",
    "import functools\n",
    "import itertools\n",
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "sns.set(style='whitegrid',font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fc552e",
   "metadata": {},
   "source": [
    "### define useful custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "045d2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define useful custom functions to ...\n",
    "\n",
    "### ... find the target tokens within tokenized sequence\n",
    "def find_sublist_index(mylist, sublist):\n",
    "    \"\"\"Find the first occurence of sublist in list.\n",
    "    Return the start and end indices of sublist in list\"\"\"\n",
    "\n",
    "    for i in range(len(mylist)):\n",
    "        if mylist[i] == sublist[0] and mylist[i:i+len(sublist)] == sublist:\n",
    "            return i, i+len(sublist)\n",
    "    return None\n",
    "\n",
    "@functools.lru_cache(maxsize=None)  # This will cache results, handy later...\n",
    "\n",
    "\n",
    "### ... grab the embeddings for your target tokens\n",
    "def get_embedding(model, tokenizer, sentence, target, layer, device):\n",
    "    \"\"\"Get a token embedding for target in sentence\"\"\"\n",
    "    \n",
    "    # Tokenize sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # Tokenize target\n",
    "    target_enc = tokenizer.encode(target, return_tensors=\"pt\",\n",
    "                                  add_special_tokens=False).to(device)\n",
    "    \n",
    "    # Get indices of target in input tokens\n",
    "    target_inds = find_sublist_index(\n",
    "        inputs[\"input_ids\"][0].tolist(),\n",
    "        target_enc[0].tolist()\n",
    "    )\n",
    "\n",
    "    # Run model\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "        hidden_states = output.hidden_states\n",
    "\n",
    "    # Get layer\n",
    "    selected_layer = hidden_states[layer][0]\n",
    "\n",
    "    #grab just the embeddings for your target word's token(s)\n",
    "    token_embeddings = selected_layer[target_inds[0]:target_inds[1]]\n",
    "\n",
    "    #if a word is represented by >1 tokens, take mean\n",
    "    #across the multiple tokens' embeddings\n",
    "    embedding = torch.mean(token_embeddings, dim=0)\n",
    "    \n",
    "    return embedding\n",
    "\n",
    "### ... grab the number of trainable parameters in the model\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"credit: https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\"\"\"\n",
    "    \n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        \n",
    "        # if the param is not trainable, skip it\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        \n",
    "        # otherwise, count it towards your number of params\n",
    "        params = parameter.numel()\n",
    "        total_params += params\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    \n",
    "    return total_params\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a7e6a",
   "metadata": {},
   "source": [
    "### load the dataframe of sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89380ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "812"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stimpath = \"../data/raw/\"\n",
    "df = pd.read_csv(os.path.join(stimpath,\"sawc_sentence_pairs.csv\"))\n",
    "\n",
    "df.shape[0] # number of sentence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ec19640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['papel',\n",
       " 'tabla',\n",
       " 'rosa',\n",
       " 'volumen',\n",
       " 'frase',\n",
       " 'clave',\n",
       " 'capa',\n",
       " 'taco',\n",
       " 'corazón',\n",
       " 'ala',\n",
       " 'sostén',\n",
       " 'pluma',\n",
       " 'cuerdas',\n",
       " 'pista',\n",
       " 'nota',\n",
       " 'cadena',\n",
       " 'papa',\n",
       " 'cartel',\n",
       " 'banco',\n",
       " 'gato',\n",
       " 'copa',\n",
       " 'naranja',\n",
       " 'título',\n",
       " 'tecla',\n",
       " 'cura',\n",
       " 'sirena',\n",
       " 'clase',\n",
       " 'caudal',\n",
       " 'pieza',\n",
       " 'pupila',\n",
       " 'vela',\n",
       " 'pico',\n",
       " 'baño',\n",
       " 'frente',\n",
       " 'código',\n",
       " 'fortuna',\n",
       " 'hábito',\n",
       " 'sierra',\n",
       " 'llama',\n",
       " 'resistencia',\n",
       " 'mano',\n",
       " 'corte',\n",
       " 'pastor',\n",
       " 'raya',\n",
       " 'perfil',\n",
       " 'periódico',\n",
       " 'planta',\n",
       " 'cinta',\n",
       " 'casco',\n",
       " 'arte',\n",
       " 'sangre',\n",
       " 'capital',\n",
       " 'canal',\n",
       " 'vaso',\n",
       " 'función',\n",
       " 'compañía',\n",
       " 'estado',\n",
       " 'orden',\n",
       " 'caja',\n",
       " 'nave',\n",
       " 'carrera',\n",
       " 'pasta',\n",
       " 'patrón',\n",
       " 'campo',\n",
       " 'químico',\n",
       " 'sueño',\n",
       " 'serie',\n",
       " 'muñeca',\n",
       " 'fibra',\n",
       " 'colonia',\n",
       " 'parque',\n",
       " 'cima',\n",
       " 'calle',\n",
       " 'guardia',\n",
       " 'ola',\n",
       " 'semilla',\n",
       " 'pata',\n",
       " 'algodón',\n",
       " 'cubo',\n",
       " 'revista',\n",
       " 'columna',\n",
       " 'hoja',\n",
       " 'lengua',\n",
       " 'seno',\n",
       " 'depresión',\n",
       " 'compás',\n",
       " 'guía',\n",
       " 'cuadro',\n",
       " 'cámara',\n",
       " 'posición',\n",
       " 'red',\n",
       " 'corteza',\n",
       " 'órgano',\n",
       " 'rama',\n",
       " 'firma',\n",
       " 'fondo',\n",
       " 'redada',\n",
       " 'cordón',\n",
       " 'aceite',\n",
       " 'clima',\n",
       " 'prima',\n",
       " 'palma']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(df[\"Word\"].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afeac0",
   "metadata": {},
   "source": [
    "### load your models and tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3179d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the url paths to download your desired models\n",
    "#.  from Hugging Face\n",
    "\n",
    "MODELS = [\"dccuchile/bert-base-spanish-wwm-cased\",\n",
    "          \"google-bert/bert-base-multilingual-cased\",\n",
    "          \"FacebookAI/xlm-roberta-base\",\n",
    "          \"dccuchile/albert-tiny-spanish\",\n",
    "          \"dccuchile/albert-base-spanish\",\n",
    "          \"dccuchile/albert-large-spanish\",\n",
    "          \"dccuchile/albert-xlarge-spanish\",\n",
    "          \"dccuchile/albert-xxlarge-spanish\",\n",
    "          \"PlanTL-GOB-ES/roberta-base-bne\",\n",
    "          \"PlanTL-GOB-ES/roberta-large-bne\",\n",
    "          \"dccuchile/bert-base-spanish-wwm-uncased\", \n",
    "          \"dccuchile/distilbert-base-spanish-uncased\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cababaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertModel(\n",
       "  (embeddings): AlbertEmbeddings(\n",
       "    (word_embeddings): Embedding(31000, 128, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 128)\n",
       "    (token_type_embeddings): Embedding(2, 128)\n",
       "    (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0, inplace=False)\n",
       "  )\n",
       "  (encoder): AlbertTransformer(\n",
       "    (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "    (albert_layer_groups): ModuleList(\n",
       "      (0): AlbertLayerGroup(\n",
       "        (albert_layers): ModuleList(\n",
       "          (0): AlbertLayer(\n",
       "            (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (attention): AlbertAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (attention_dropout): Dropout(p=0, inplace=False)\n",
       "              (output_dropout): Dropout(p=0, inplace=False)\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            )\n",
       "            (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "            (dropout): Dropout(p=0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (pooler_activation): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath = \"dccuchile/albert-base-spanish\"\n",
    "model = transformers.AutoModel.from_pretrained(mpath,output_hidden_states=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5a2c14",
   "metadata": {},
   "source": [
    "### compute cosine distances\n",
    "\n",
    "for each target word within a pair of sentences, for each model layer, for each model specified in the `MODELS` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e5233c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be415b2b8d204780b0229e617d8dd2f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2acaf0b13341c3ada7ca4ffc22e7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d5c031f3dc4446af2b2922c829bb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b8e2d3fa9848888d5d54986938be95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/851k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "811323a8b90b4c3e80a731bd30eecc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/509k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5444dae0f93498785bae670a188f72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287c3352f6564cb78bd57555078e8601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers: 12\n",
      "Total Trainable Params: 124643328\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e12fdb12f3450da8673d4123ce26e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51647db6a6474755899b4c4a89a0e7ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62b12f2887e497c94ba0ad8f8a45f41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e2a46560584ca0aa7cd6486b9afddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5507698f3cf43408743bc54da1905d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42b02c7de004acc83563a779585be3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb41c823b48a47a0bcec786c8fc764b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2077f06294ee41759ed960c9f4ab2b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be264cafd0d4834b16c6cf1c35a817d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace6ab384b7b41e9949147e72f8a40f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a87d7bead974cc6ac8c149e53aae97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2227f8bdfef947cb82e208107bc4325a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fe9b05002d4946b065fb7d9b90d964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4362a4e03ff46d985c27cb1de7a88f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427a2e65d21a4556821d155f3e348a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-large-bne and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7428159a882744b38c3df2825df4e8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d848e9d6fb104b4ca3a2c05cf7e9e676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/858k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7b84a19ab14aaab8490a9da24177a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/516k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c03d23785445c8adcdb4ba0fabaade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98643f2e60c4f75ad2c16afffadc7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers: 24\n",
      "Total Trainable Params: 355356672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e94ed964be84f698fd40910c962dc95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f2cf96fa3546a28ffb208e5929616b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54061ccb5fe400486aab1d2c16e4c7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb771ed30594be2aa961b320266d87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a4363ccceb4bfba71e8f10db8e7d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9dc2019ba1f435d8393a3948ad39521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c369b9428880467495a5c21c80ae1711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1140ac8f154af082ec88ebdb0e989f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a958c64671848d59d8e1dedd5a3cea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fc48c4a5a64fe1adf807a24bf3790b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5924cf76004f4e91b12bd70c385e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ae21817f654db2837780c73d7dfd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90740126a9e47189fe33735a1d7dc62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4640a9f08184741a412ea5b0a3a479e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9887d8ac1fb45aabb86f67b7f519c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e409529c584b07b88885527f392355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3664044960a47839bd9ef66d4624e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06599fcecef94cdaa93bd7c084eb1d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7909a8ae866744d385a57fc831c5507f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "973ff737827a4af387ac286a9ec285d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3d882b1b05443eb42ccd87c209ed97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0228cea475394d32a7073781b7ed6467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66581e2ce5b4f9a8b9ffc57d457cc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4809643c9313483298d05cca352c358f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce7a497b7904701887c679e6f316f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-uncased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers: 12\n",
      "Total Trainable Params: 109850880\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c5c243124f4bd8a7afd1d0b2ef04ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb1bfc4e5f84f1b9ffa66e57aac1e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b12057c09a4b9ebe7e538551413e62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25465cbe92de4300842604dc1efafe8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8280b72bc53840ae8e1e736c591041c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e7997d50d649cf9fd36d60de83c3e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68061153f3e94938a3815d074002bed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3d6707480f46dca41165ea00d3d683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38f8daa56004e0c9a8e1bb1b5463431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b2c23cd320944598ae2150068097d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f4ef6b2ce942c38ca4a612bd98656b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cd1c3d809f4db4b067ae128ecfdf9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e65c915d604a24b4980b6a459ba5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1a42d6df33487dafc664c153b16c53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/530 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8e5ea1cc5f42819de4491c74444c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/269M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b34e2f51584db49043ab419b56dd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/361 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7ed97698cf471fa78d322deac75ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a780919bfd15409db41409f98dcef433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/486k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c0a3673e0c49c990b4242367a16033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of layers: 6\n",
      "Total Trainable Params: 66338304\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d4ec2dcd404e9dbff40d66dfafce50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70dda61213046cb8f1d8b150f37f689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f60a6e2ffc54ab6ad686cc34105bd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee862065aa5446894c0a0fc61c2067b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2735da3de5e349b6a565c78652f22dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6e64386f59498fb041b67b75c66118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8f88f3b2644614930cd6822d094f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/812 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Iterate over models and do the work! \n",
    "\n",
    "for mpath in tqdm(MODELS,colour=\"cornflowerblue\"):\n",
    "\n",
    "    ### Decide which device you want the models to run in\n",
    "    \n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "    ### Load your model & tokenizer\n",
    "    \n",
    "    model = transformers.AutoModel.from_pretrained(mpath,output_hidden_states=True)\n",
    "    model.to(device) # allocate model to desired device\n",
    "\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(mpath)  \n",
    "    \n",
    "    \n",
    "    ### Get the number of layers & params directly from the model specifications\n",
    "    \n",
    "    # TODO: Double-check for all configurations\n",
    "    \n",
    "    n_layers = model.config.num_hidden_layers\n",
    "    print(\"number of layers:\", n_layers)\n",
    "\n",
    "    n_params = count_parameters(model)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for layer in range(n_layers+1): # `range` is non-inclusive for the last value of interval\n",
    "        for (ix, row) in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "\n",
    "            ### Get embeddings for S1 and S2\n",
    "\n",
    "            # note: account for tokenization differences in RoBERTa Spanish monolinguals  by\n",
    "            #.      adding a whitespace in front of the target word (otherwise, the function\n",
    "            #.      `find_sublist_index` will not be able to identify the target token-s within\n",
    "            #.      the tokenized sentence)\n",
    "            \n",
    "            if mpath in [\"PlanTL-GOB-ES/roberta-base-bne\", \"PlanTL-GOB-ES/roberta-large-bne\"]:\n",
    "                target = \" {w}\".format(w = row['Word'])\n",
    "            else:\n",
    "                target = row['Word']\n",
    "\n",
    "            s1 = get_embedding(model, tokenizer, row['Sentence_1'], target,layer, device)\n",
    "            s2 = get_embedding(model, tokenizer, row['Sentence_2'], target,layer, device)\n",
    "\n",
    "            ### Now calculate cosine distance \n",
    "            #.  note, tensors need to be copied to cpu to make this run;\n",
    "            #.  still faster to do this copy than to just have everything\n",
    "            #.  running on the cpu\n",
    "            if device.type == \"mps\":  \n",
    "                model_cosine = cosine(s1.cpu(), s2.cpu())\n",
    "\n",
    "            else: \n",
    "                model_cosine = cosine(s1, s2)\n",
    "\n",
    "\n",
    "            ### Figure out how many tokens you're\n",
    "            ### comparing across sentences\n",
    "            n_tokens_s1 = len(tokenizer.encode(row['Sentence_1']))\n",
    "            n_tokens_s2 = len(tokenizer.encode(row['Sentence_2']))\n",
    "\n",
    "            ### Add to results dictionary\n",
    "            results.append({\n",
    "                'Sentence_1': row['Sentence_1'],\n",
    "                'Sentence_2': row['Sentence_2'],\n",
    "                'Word': row['Word'],\n",
    "                'Same_sense': row['Same_sense'],\n",
    "                'Distance': model_cosine,\n",
    "                'Layer': layer,\n",
    "                'S1_ntokens': n_tokens_s1,\n",
    "                'S2_ntokens': n_tokens_s2\n",
    "            })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results['token_diffs'] = np.abs(df_results['S1_ntokens'].values-df_results['S2_ntokens'].values)\n",
    "    df_results['n_params'] = np.repeat(n_params,df_results.shape[0])\n",
    "    \n",
    "    \n",
    "    ### Hurray! Save your cosine distance results to load into R\n",
    "    #.  for analysis\n",
    "\n",
    "    savepath = \"../data/processed/models/\"\n",
    "    if not os.path.exists(savepath): \n",
    "        os.mkdir(savepath)\n",
    "\n",
    "    filename = \"sawc-distances_model-\" + mpath.split(\"/\")[1] + \".csv\"\n",
    "\n",
    "    df_results.to_csv(os.path.join(savepath,filename), index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
