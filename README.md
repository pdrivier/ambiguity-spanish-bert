# ambiguity-spanish-bert
Using lexical ambiguity to probe BERT contextualized representations

We use lexical ambiguity—where one word conveys multiple meanings—to probe BERT-based models’ ability to contextualize word representations, measured against a human baseline on a new dataset of minimal-pair sentences which conveyed either the same or different sense for a target ambiguous word. 

The code and data available in this repository corresponds to work in the following preprint: [https://arxiv.org/pdf/2406.14678](url). 
